\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\graphicspath{{images/}{../images/}}

\title{Philosophy Summary}
\author{Jacob Burley}
\date{Block 5 2019}

\begin{document}

\maketitle

\tableofcontents
\newpage
\section{Introduction}
Ethics is the discipline of philosophy that studies morals (moral philosophy)
\\We can study morality in three different ways:
\begin{itemize}
    \item \textbf{Descriptively}: How do people behave, what causes their behaviour?
    \item \textbf{Normatively}: How should they behave, and how should they justify their behaviour?
    \item \textbf{Meta-ethically}: What kind of statements are moral statements? Do they have truth values? What are moral properties?
\end{itemize}{}
Values are used in philosophy:
\begin{itemize}
    \item Freedom
    \item Knowledge
    \item Friendship
    \item Love
    \item Beauty
    \item Equality
    \item Happiness, wellbeing
    \item ...
\end{itemize}{}
Different branches of philosophy have different views as to how these values relate to eachother.
\begin{itemize}
    \item \textbf{Monism}: These values reduce to one intrinsic, fundamental value. Other values are only instrumental
    \item \textbf{Pluralism}: Each of these values is \textit{irreducible}, because each value is intrinsic
\end{itemize}
If we choose to focus on well-being and happiness, and evaluate actions based on how much wellbeing they cause, we must have an idea of what we mean by wellbeing.

    \subsection{Theories of Wellbeing/Happiness}
    \begin{enumerate}
        \item \textbf{Hedonism}
        \item \textbf{Preference Satisfaction}
        \item \textbf{Objective list}: Wellbeing consists of some items on an objective list that hold universally.
    \end{enumerate}{}

        \subsubsection{Hedonism}
        \begin{itemize}
            \item \textbf{Hedonism}: Wellbeing is the pleasure of an indidual summed with their pain.
            \item Source of this wellbeing is irrelevant
            \item Hedonists: Epicurus (341BC - 271BC), Bentham (1748 - 1832), Mill (1806 - 1873)
        \end{itemize}{}
        \textbf{Objections to Hedonism}
        \begin{itemize}
            \item Wellbeing doesn't always come from an inner feeling. Positive feelings can be had from external sources (looking at art, mastering a skill).
            \item \textbf{Robert Nozick}'s \textbf{Experience Machine}
            \begin{itemize}
                \item You plan out a life for yourself, then enter a machine for 30 years and live that life. When you leave, do you still have the same sense of wellbeing?
                \item Thought experiment shows that if wellbeing came from inside, you wouldn't any sadder after leaving the machine.
            \end{itemize}{}
            \item Nozick says that people would not want to enter the machine, because:
            \begin{itemize}
                \item They want to live a \textbf{real life}
                \item They want to be a \textbf{person}, not just a heap of organic matter
                \item They want to \textbf{do} things, instead of just experiencing them
            \end{itemize}{}
            \item Wellbeing has distinct forms. Wellbeing from being with friends is different than wellbeing from reading a good book
            \begin{itemize}
                \item John Stuart Mill gives that some of these forms are better than others: "It is better to be Socrates unhappy than pig happy."
                \item Jeremy Bentham disagrees: "Pushpin (a simple board game) is just as good as poetry."
            \end{itemize}{}
            \item Hedonistic treadmill means that the dopamine from the same source of wellbeing will eventually decrease, leading to the indefinite seeking of stronger stimuli to provide this wellbeing
            \item We can't accurately measure or compare hedonistic states
            \item Above leads to the idea of \textbf{Preference Satisfaction}
        \end{itemize}{}


        \subsubsection{Preference Satisfaction}
        Wellbeing is how well an individuals preference are satisfied. This shouldn't be interpreted hedonistically: satisfying as in satisfying requirements.
        \\Modern theory suggests that preference satisfaction = utility
        \\We can determine this with an ordinal scale, Von Neumann Morgenstein interval scale
        \bigbreak
        \textbf{Criticism}
        \begin{itemize}
            \item Uninformed preferences
            \begin{itemize}
                \item People like(d) to smoke, and for a long time weren't aware of the consequences. Side effects aren't apparent or easily considered
            \end{itemize}{}
            \item Adaptive Preferences 
            \begin{itemize}
                \item our preferences adapt to our circumstances
                \item Slaves can be happy because they have not been injured recently, prisoners happy because the food was good recently.
            \end{itemize}{}
            \item \textbf{Modification}: Only rational and informed preferences should count (bringing us closer to the objective list)
            \item Are malevolent preferences acceptable if they count towards someones wellbeing? Should they count?
            \item There are things that may be satisfied without you being aware of them: you may hope that a charity reaches a certain funding goal, which would bring you satisfaction. You may not be aware of whether this is the case, however. So what happens with that satisfaction?
            \item Are all types of preference satisfaction equal?
            \item How can we compare utility/wellbeing among people?
        \end{itemize}{}
        
        
        
        \subsubsection{Objective List}
        Wellbeing consists of some items on an objective list that hold universally.
        \\\textbf{Objective list of Basic Needs}, e.g.
        \begin{itemize}
            \item food
            \item drink
            \item income
            \item shelter
            \item social relations
        \end{itemize}{}
        \bigbreak \textbf{Objective list of things that make people flourish}, e.g.
        \begin{itemize}
            \item education
            \item culture
            \item sport
            \item freedom
            \item having a voice
            \item clubs/communal activities
        \end{itemize}
        \bigbreak \textbf{Objective list of Capabilities} (what people can do) - Sen, Nussbaum
        \begin{itemize}
            \item Physical Health
            \item Bodily integrity
            \item Making use of the senses
            \item Imagination and thought
            \item Express emotions
        \end{itemize}{}
        We can use this lists to illustrate a difference between individuals, and then account for these differences i.e. by giving someone with bad eyesight extra money so they can buy glasses
        \\This way everyone is on equal footing in terms of wellbeing
        \\In general, objective lists don't have any intra/interpersonal measurement problems, because it is binary whether someone has the thing or not.
        \\This makes them easy to use for policy makers, because it is easy to determine what is yet to be satisfied
        \bigbreak \textbf{Objections to objective lists}
        \begin{itemize}
            \item Are the items on the list correct?
            \item How do we justify adding/removing items from the list (how do we determine whether people want them? Preference Satisfaction)
            \item The items do not constitute wellbeing, they \textbf{are} sources of wellbeing
            \item People have authority over their wellbeing
            \item These lists are not sensitive to the differences between people
        \end{itemize}{}
    
    \subsection{Subjectivism}
    \begin{itemize}
        \item Moral statements are just expressions of personal opinion or taste
        \item They don't convey matters of fact
        \item They do not have truth values, and cannot be true or false
    \end{itemize}{}
    In meta-ethics, the position that moral statements don't have truth values is commonly known as \textbf{non-cognitivism}, but an earlier and simpler version is \textbf{Emotivism}.
        \subsubsection{Emotivism}
        \begin{itemize}
            \item Moral statements are expressions of emotions: approval, disapproval
            \item These statements don't have truth values
            \item Moral disagreement here is a \textbf{conflict of attitudes}. These disagreements are hard to reconcile, as they run deep.
            \item Difference in moral judgments explained by variety of attitudes
            \item Morality motivates: this is difficult for cognitivists, but not for emotivists.
        \end{itemize}{}
        \bigbreak \textbf{Objections}
        \begin{enumerate}
            \item Moral reasoning between people is an exchange of arguments instead of attitudes
            \begin{itemize}
                \item Moral reasoning doesn't resemble a combination of expressions of emotions
                \item Emotivist arguing does not reflect the logical structure of a problem (\textit{Free-Geach} problem)
            \end{itemize}{}
            \item How do we distinguish moral statements from other evaluative statements in a non-circular way?
        \end{enumerate}{}
        Modern non-cognitivism is more sophisticated, with \textbf{Norm Expression} (\textit{Alan Gibbard}, and \textbf{Quasi Realism} (Simon Blackburn)
    
    \subsection{Relativism}
    \begin{itemize}
        \item Cultural Relativism: Different cultures vary in systems of moral norms
        \item This does \textbf{not} mean that there is no culture independent universal morality, however.
        \begin{itemize}
            \item Perhaps there is, and no culture has yet discovered this system of universal norms
            \item Perhaps the varying systems of norms of varying cultures are rooted in a (more fundamental) system of universal norms than has been considered before
        \end{itemize}{}
    \end{itemize}{}
    \subsubsection{Moral Relativism}
    \begin{itemize}
        \item variant of cognitivism
        \item Moral statements \textbf{do} have truth values, and are true or false
        \item These values are relative to a specific culture
    \end{itemize}
    \bigbreak \textbf{Objections}
    \begin{itemize}
        \item Some values and norms \textit{actually are} common to all cultures
        \item There isn't an objective standpoint to criticize the morality of a specific culture (we can't objectively say that a critic is above another culture), and we can't actually settle a discussion between members from different cultures
        \item Is the idea of moral progress still possible?
    \end{itemize}{}
    \subsubsection{Normative Relativism - a measured response?}
    We can attempt to deal with the fact that there is no known set of universal norms
    \begin{itemize}
        \item "Each culture should have its own morality"
        \item "One should be tolerant of different cultures"
    \end{itemize}{}
    Both of the above claims are universal, and don't follow from moral relativism. A moral relativist can also say that one \textit{shouldn't} be tolerant.

\section{Decision Theory (and Game Theory)}
    There are three branches of decision theory to cover here:
    \begin{itemize}
        \item \textbf{Individual Decision Theory}: studies decision making when the actors are confronted with various "states of nature"
        \item \textbf{Game theory}: studies decision making when actors interact with \textit{eachother}
        \item \textbf{Social Choice Theory}: Studies how to derive a collective decision from individual preferences (\textbf{we don't cover this in this course})
    \end{itemize}
    \textbf{Rational Actor}
    Mental states of a (rational) actor fall into two basic categories:
    \begin{itemize}
        \item \textbf{Beliefs}: mind-to-world direction of fit, the goal is that mental content mirrors the world (beer exists, therefore we believe it is there)
        \item \textbf{Desires}: world-to-mind direction of fit, ideally the world would mirror the mental content (we want a beer, but it doesn't exist in the world yet, so we ask the bartender for a beer, realizing our desire)
    \end{itemize}
    Elizabeth Anscombe: "Desire like a shopping list, believe like an inventory"
    \bigbreak \textbf{Actors have:}
    \begin{itemize}
        \item desires
        \item beliefs
        \item rationality
    \end{itemize}{}
    Formalizing in decision theory, we get:
    \begin{itemize}
        \item preferences over outcomes
        \item assign probabilities to these outcomes
        \item these satisfy consistency requirements (the axioms of the theory)
    \end{itemize}
    \bigbreak \textbf{Decision making can be studied}:
    \begin{itemize}
        \item \textbf{Descriptively}: psychology, behavioural economics both study how people \textit{actually} make choices, in labor or in the field.
        \item \textbf{Normatively}: Decision theory studies how people \textit{should} make decisions.
    \end{itemize}
    \bigbreak \textbf{A formalized decision problem}
    Formalizing a decision problem gives us 3 things:
    \begin{itemize}
        \item Actions
        \item States
        \item Outcomes
    \end{itemize}
    An Action : function(state) = outcome
    \\An action, performed in/on a given state leads to an outcome. We can represent this in a table, a tree or a vector.
    \subsection{A Decision Table}
    You contemplate studying medicine or going to dance academy. You reason that going to a dance academy may result in an exciting life but only when the economy is not in a recession. Because then, the budgets for culture will be cut and you will be poorer. Becoming a doctor in a growing economy gets you a good life and under a recession it will still offer you a reasonably good life.
    \\We can represent these outcomes in a \textbf{Decision Table}.
        \begin{table}[h!]
        \begin{tabular}{l|llll}
                      & Recession       & No recession &  &  \\ \hline
        Dance Academy & poor            & exciting     &  &  \\
        Medicine      & reasonably good & good         &  &  \\
                      &                 &              &  & 
        \end{tabular}
        \end{table}
    \subsection{Decision making under ignorance}
    You can make uninformed decisions, instead of knowing the probabilities, using the following strategies:
    \begin{itemize}
        \item Dominance
        \item Maximin/leximin
        \item Maximax
        \item Minimax regret
        \item Insufficient Reason
        \item Optimism-Pessism
    \end{itemize}
    We only need to look at Maximin as part of this course.
    \bigbreak \textbf{Maximin: Avoiding the worst case scenario}
    \begin{table}[h!]
    \begin{tabular}{l|llll}
       & S1 & S2 & S3  & S4 \\ \hline
    A1 & 1  & -3 & 5   & 6  \\
    A2 & 2  & 2  & 3   & 3  \\
    A3 & 4  & 6  & -10 & 5 
    \end{tabular}
    \end{table}    
    \\In Maximin, we pick the \textbf{lowest} number in each of the \textit{rows}, and then pick the \textbf{highest} number from those numbers. In this way, we avoid the worst case scenario (which would be the lowest of the lowest). We choose the \textbf{Maxi}mum \textbf{Min}imum.
    
    \subsection{Decision Making under risk}
    In this scenario, a rational actor has knowledge of the probabilities.
    \\A standard rule to maximize expected utility here would be: Max(Probability * Utility)
    %TODO: is the above right?
    \\We can also use this with money, time, etc if utility is a linear function of this factor, i.e there is a linear correlation between the factor and utility.
    %TODO: what the fuck?? does this mean
    
    \subsection{Scales for utility (and their axioms)}
    \begin{itemize}
        \item Ordinal Utility Function: preferences must satisfy 3 axioms
        \begin{itemize}
            \item Asymmetry
            \item Completeness
            \item Transitivity
        \end{itemize}
        \item Interval Utility Function: satisfies the above axioms, as well as
        \begin{itemize}
            \item Independence
            \item Continuity
        \end{itemize}{}
    \end{itemize}{}


\section{Consequentialism \& Utilitarianism}
Person $\longrightarrow$ Action $\longrightarrow$ Consequences
\bigbreak There are four \textbf{Normative Ethical Theories} that we will cover in this course:
\begin{enumerate}
    \item \textbf{Consequentialism, Utilitarianism}: Focuses on the Consequences
    \item \textbf{Deontology}: Focuses on the Action
    \item \textbf{Social Contract Theory}: Focuses on the interdependency between actors
    \item \textbf{Virtue Ethics}: Focuses on the Person
\end{enumerate}{}

    \subsection{Consequentialism}
    \textbf{Moral Worth is in the consequences of the action}
    \begin{itemize}
        \item The values that are realized by the action give moral worth
        \item An action is morally good if it has good consequences, given possible actions %so if all the possible actions are bad, there is still moral good?
        \item Can be \textbf{monistic} or \textbf{pluralistic} in terms of states
        \item Values can be maximized, but this isn't necessarily the case (i.e., \textit{egalitarians} want even spread of values among all people
    \end{itemize}

    \subsection{Utilitarianism}
    Is a subset of consequentialism.
    \\Only \textbf{monistic}: only utility(wellbeing) counts when we consider the good an action does, any other benefits aren't considered benefits
    \\Maximises utility
    \\Definition of what utility may be defined as is in chapter 1.
    \\Bentham says: "this fundamental axiom, it is the greatest happiness of the greatest number that is the measure of right and wrong"
    \\Mill says: "Utility, or the Greatest Happiness Principle, holds that actions are right in proportion as they tend to promote happiness, wrong as they tend to produce the reverse of happiness"
    
        \subsubsection{Putting Utilitarianism to work}
        \begin{enumerate}
            \item Define your concept of utility: do you use hedonism? Preference Satisfaction? Perhaps an Objective List?
            \item What are the possible alternative actions to an action?
            \item Determine the total expected utility for each alternative action:
            \begin{itemize}
                \item Expected Utility = Probability $\times$ utility
                \item Total = aggregate utility of all individuals affected by the action
            \end{itemize}{}
            \item The action with the highest Total Utility is the \textbf{Morally Good action}, which is the action that should be performed.
        \end{enumerate}{}
        
        \subsubsection{Important Characteristics of Utilitarianism}
        \begin{itemize}
            \item Utilitarianism is \textbf{impartial}: noone has more privilege than another person in a utilitarian society
            \begin{itemize}
                \item Anyone who can be more/less happy (anyone who can suffer) belongs to the moral community
                \item This provides an argumentative basis for: Women's right to vote, abolition of slavery, animal rights/welfare
            \end{itemize}{}
            \item Utilitarianism is also \textbf{flexible} with regards to traditional morals
            \begin{itemize}
                \item Lying, stealing etc are generally considered "\textit{Traditional Morals}" (i.e. from 10 Commandments)
                \item These actions are permissible under utilitarianism, \textbf{if} they increase total utility.
            \end{itemize}{}
            \item \textbf{Forward Looking}: consequences are in the future, making the past irrelevant.
            \begin{itemize}
                \item Imprison people for crimes so they can rehabilitate, and help increase future utility. People don't inherently deserve punishment for creating bad utility unless that will help create future utility
            \end{itemize}{}
            \item Utilitarianism is \textbf{insatiable}: There is never too much utility (unless we consider \textit{satisficing utilitarianism}
        \end{itemize}{}
        
        \subsubsection{Criticism and Discussion}
        \begin{itemize}
            \item Utility might not be all that matters, there may be other intrinsic values worth increasing. (Is the completeness axiom thus correct?)
            \item Is it acceptable to bend rules such as "thou shalt not steal", even if it increases utility? Is it not wrong to sacrifice the wellbeing of some innocent people in order to maximize (overall) utility?
            \item It isn't realistic to actually calculate the expected utility for each situation (although Chidi tried his best)
            \item People are people, and aren't just vessels to carry utility. They have integrity and seperateness/individuality
            \item Backwards looking reasons are important. An individual may deserve punishment for their crimes
            \item Special relations between individuals are important. On a micro scale, everyone may be equal, but in the macro view of each individual, there are others who have more importance and priority than strangers (i.e. friends, family)
        \end{itemize}{}
        \subsubsection{Utilitarian Responses to Criticism}
        \begin{itemize}
            \item Singer says we should bite the bullet: "Most criticism is an irrational product of our evolutionary and cultural past"
            \item We can make modifications (i.e. \textbf{indirect / rule utilitarianism})
            \item Utilitarians argue that: $$\textrm{Total Utility}_{\textrm{everybody utilitarian calculating}} < \textrm{Total Utility}_{\textrm{everybody follows rules}}$$
            \item System of rules that apply to all in a society
        \end{itemize}{}
        %TODO for this section: Indirect/rule utilitarianism
        \subsubsection{Indirect / Rule Utilitarianism Discussion}
        %he literally didn't cover this in the lecture afaik
        \begin{itemize}
            \item Must a rule always be followed? Even if it doesn't yield the maximum utility possible?
            \begin{itemize}
                \item Response to this is that these are rules of thumb: we should follow these rules as long as there is no reason to reconsider
                \item Utilitarian calculus $\longrightarrow$ design system of global rules to Max(Utility)
            \end{itemize}
            \item What we do in actual situations is derived from a hypothetical situation where the rule fits perfectly
            \item Do rules provide appropriate moral justification? Is following rules \textit{the} most moral thing?
            \begin{itemize}
                \item If you save your own child instead of two others, you do this because a rule is part of a system that maximizes Utility
                \item Bernard Williams asks: "Isn't that one thought too many?" Should we have to think about the rules before we act?
            \end{itemize}
        \end{itemize}

\section{Deontology and Social Contract Theory}        
    \subsection{Deontology}
    Founding father was Immanuel Kant (1724 - 1804). He gave that "\textit{moral worth is not to be found in the consequences of an action}". E.g. lying or stealing or killing is not bad because these actions have bad consequences. They are simply inherently bad actions, and therefore should not be done.
    \\People should act \textit{out of duty}, i.e. not because of any external motivation. They act because it is the \textit{right thing to do} in a situation. Moral worth is then clearly shown when duty is fulfilled, even if it clouds the actors mood.
    \\Doing the right thing is formal in Kant's eyes. The principle underlying the right intentions should be lawlike, like a natural law, except this is a law humans impose on themselves. This distinguishes humans from animals, who are subject to natural laws and are driven by inclinations and impulses. Humans are able to impose laws and rules on themselves, and follow them. This gives humans \textbf{freedom}.
        \subsubsection{Kant and Newton}
        Isaac Newton gives that "Ëverything in the universe is subject to natural laws"
        \\Kant gives that "Morality has universal scope and necessity" just like Newton's laws, with the difference being that humans impose these laws on themselves.
        
        \subsubsection{Categorical Imperatives}
        \begin{enumerate}
            \item \textbf{Universal Law Formulation}
            \begin{itemize}
                \item Before performing an action, ask yourself what it would be like if \textit{everyone} also performed that action
                \item Categorical: not dependent on context, just like laws.
                \item How can an action be a good action for you if you wouldn't want everyone else to act like that?
            \end{itemize}{}
            \item \textbf{Humanity Formulation}
            \begin{itemize}
                \item Other humans aren't a source of utility, and should be treated as an end instead of a means. They are not commodities
                \item This formulation prohibits lying (breaking promises/contracts) because then you are treating another person as vehicle for your purposes.
            \end{itemize}
        \end{enumerate}{}
        How are 1 and 2 related? Kant argues that various versions of the CI are equivalent, but this is unclear. 
        \\One argument gives that a rational creature (one who self-governs by imposing laws on itself) must respect this rational nature, as it is a distinguishing feature of itself.
        
        \subsubsection{Criticism and Discussion}
        \begin{enumerate}
            \item Should moral rules be this absolute? Should lies sometimes be permitted i.e. to prevent a murder?
            \item Wellbeing/happiness does not play into this moral status
            \begin{itemize}
                \item Response: Increasing wellbeing is allowed, assuming it is not otherwise disallowed by the CI.
            \end{itemize}{}
            \item Creatures that are less rational fall outside of the moral community (i.e. children, animals, cognitively impaired)
            \item What do we do if rules conflict? i.e. you can't lie that you killed someone to appease someone who wanted you to kill
        \end{enumerate}{}
    
    \subsection{Social Contract Theory}
    Morality is social, so the moral reasons of people are interdependent.
    \\Morality = A system of mutual expectations and preferences, used to solve cooperation problems (the most notable of these being the provision of collective goods in a society)
        \subsubsection{Collective Goods}
        These are goods that can \textbf{only} be produced by cooperation. Once produced, everyone can benefit from these goods. This means that they are vulnerable to \textbf{free riding}, where people do not contribute towards the production of a good but utilize it nonetheless.
        \\There is no moral obligation to allow yourself to be exploited. Choices that benefit the group should only be made if you are sure that others will do the same.
        \begin{table}[h!]
        \begin{tabular}{l|llll}
                              & Contribute      & Don't Contribute  \\ \hline
        Contribute            & C,C             & D,C               \\
        Don't Contribute      & C,D             & D,D                                 
        \end{tabular}
        \end{table}
        \\Collectively, we would rather be at C,C than D,D, because then we all contribute to a collective good. However, if you contribute and someone else doesn't, you end up in C,D, thus being exploited because you have to contribute to the good and the other party does not. For you then, you would rather be at D,D, where you do not have to contribute but also do not have to be exploited.
        
        \subsection{Thomas Hobbes}
        (1588 - 1679), founding father of Social Contract Theory. He had a central question: People \textbf{must} reach a mutual agreement in order to avoid a war of all against all. What set of rules can we use to avoid this state, and how can we make sure the rules are followed? A war of all against all is the same as the state D,D above.
        \subsubsection{Hobbes' Central Question}
        There are multiple Nash equilibria that can be used as solutions for this problem. A law is a system of rules that reduces these various Nash equilibria.
        
            \subsubsection{Hobbesian Social Contract Theory}
            \begin{itemize}
                \item We want to derive moral rules from rational self-interest. 
                \item Since cooperation problems are at least partially negotiable, and negotiations are sensitive to starting positions in real life:
                \begin{itemize}
                    \item Resources or capital parties bring to the bargaining table
                    \item Wealth, goods, talents, skill set, network etc
                \end{itemize}
                \item Moral rules must therefore be sensitive to various starting positions
            \end{itemize}
            
        \subsection{Tisne's Bill of Data Rights Proposal}
        Martin Tisne gives that the unrestricted use of data in the aggregate is bad for everybody, while the restricted use by everybody leads to a cooperative outcome. He believes that a \textbf{bill of data rights} is necessary.
        \begin{itemize}
            \item The right of the people to be secure against unreasonable surveillance shall not be violated
            \item No person shall have his or her behaviour surreptitiously manipulated
            \item No person shall be unfairly discriminated against on the basis of data
        \end{itemize}
        
        \subsection{Criticism and Discussion}
        \begin{itemize}
            \item Social contracts aren't real/tangible
            \begin{itemize}
                \item Social contracts should be understood to be tacit or hypothetical
            \end{itemize}
            \item People who don't/can't contribute to the cooperative project can still have moral status
            \begin{itemize}
                \item Response: Other part of morality %TODO: wtf does this mean?
            \end{itemize}{}
        \end{itemize}
        \subsection{Non-Hobbesian Social Contract Theory}
        \begin{itemize}
            \item Morality is a combination of utilitarian or Kantian motives and interdependency
            \item John Rawls (modern Kantian Social Contract Theorist):
                \begin{itemize}
                    \item "\textit{Talents and skills are a product of genes, upbringing, and are therefore morally arbitrary. As such, they should not play a role in designing a just society}"
                    \item "\textit{Therefore, we hypothesize the contract situation as if everybody reasons behind a veil of ignorance: you reason without information about the resources available to you}"
                    \item In this way, everyone should reason the same given the same situation
                    \item Rawls decision making under ignorance: maximin $\longrightarrow 2a$
                    \item Rawl has two principles of justice
                        \begin{enumerate}
                            \item \textbf{Principle of equal liberty}: Each person has the same right to the most extensive liberties that are compatible with similiar liberties for everyone else
                            \item \textbf{Difference Principle}: Social and economic inequalities should be (re)arranged so that they are both to the \textit{greatest benefit of the least advantaged persons}, and so that they are \textit{attached to offices and positions open to all under conditions of equality and oppurtunity}.
                        \end{enumerate}
                \end{itemize}
        \end{itemize}
 \section{Applications: Cost Benefit Analysis, Many Hands Problem}
    \subsection{Social Cost Benefit Analysis}
    \begin{itemize}
        \item Governments must compare policy alternatives in terms of future advantages and disadvantages
        \item Utility could be used as a metric to compare, but money is used the most often when comparing alternatives
        \item Monetize almost all of the benefits and costs, and recalculate to the same year (with interest rate)
        \item Some benefits and costs don't have a calculable market price
        \begin{itemize}
            \item Casualties, wounded in a disaster
            \item $CO_2$ emissions
            \item Noise
            \item Nature, environment
        \end{itemize}{}
    \end{itemize}{}
        
        \subsubsection{What is the Cost Benefit Analysis of Cost Benefit Analysis?}
        \textbf{Benefits}
        \begin{itemize}
            \item Rationalizes public decision making
            \item Less subjective
            \item Forces people to consider all relevant considerations
            \item Provides common ground to agree upon
        \end{itemize}
        \textbf{Costs/disadvantages}
        \begin{itemize}
            \item Never complete (never have perfect information)
            \item Some estimates are very uncertain
        \end{itemize}{}
        
        \subsubsection{Decisions based on CBA}
        \textbf{Utilitarians} decide by using the absolute difference between costs and benefits, or a ratio between them (do the costs outweigh the benefits, literally)
        \\\textbf{Non-utilitarians} may decide using constraints, or thresholds (i.e. noise from a new highway may not exceed $x$, the cost may not exceed $y$ etc.
        
    \subsection{Problem of Many Hands}
    Something bad happens as a result of collective human conduct. Who is to blame? It is difficult/impossible to determine individual responsibility. Collective responsibility is obvious, however.
        \subsubsection{Criteria for moral responsibility}
        A person is morally responsible in the event of something going wrong if:
        \begin{enumerate}
            \item They did something wrong: \textbf{Wrongdoing}
            \item They did not act under coercion, and \textit{could} have acted differently: \textbf{Freedom}
            \item They directly caused the bad state of affairs: \textbf{Causality}
            \item They knew/could have known that their action would cause a/the bad state of affairs: \textbf{Knowledge}
        \end{enumerate}{}
        
        \subsubsection{Responsibility}
        Can also be assigned to collectives, because they have or ought to have a collective aim.
        \\ Assigning responsiblity is important, for \textbf{Retribution} (a debt to those hurt is paid), \textbf{Correction} (the problem is fixed) and \textbf{Prevention} (steps are taken by those responsible to ensure it does not happen again)
        \\There are differences between collective and individual responsibility that stem from differences in the criteria for moral responsibility:
        \\\textbf{Collective}
        \begin{itemize}
            \item Wrong doing is possible
            \item Freedom is possible
            \item Causality is possible
            \item Knowledge is possible
        \end{itemize}
        \bigbreak
        \textbf{Individual}
        \begin{itemize}
            \item Wrong doing is possible
            \item Freedom is possible
            \item Causality is possible
            \item Knowledge is not necessarily possible: a lower level employee carrying out instructions may not be aware of the impact of their actions, whereas an executive might be aware.
        \end{itemize}{}
        
        \subsubsection{Three models to deal with Many Hands responsibility}
        \begin{enumerate}
            \item \textbf{Hierarchical Model}, where the top management is held responsible
            \item \textbf{Collective Model}, where each member is responsible for the whole
            \item \textbf{Individual Model}, where each member is responsible in relation to their contribution
        \end{enumerate}
 
 
 
 \section{Values and Scientific Integrity in Science}
    \subsection{Ethics in science}
    Robert Merton's \textbf{CUDOS} norms:
    \begin{enumerate}
        \item \textbf{Communism}: Science is collective, not the property of the individuals who researched it
        \item \textbf{Universalism}: Acceptance and refutation of claims happen on impersonal grounds. You can't accept/reject a theory because a researcher is your friend/foe
        \item \textbf{Disinterestedness}: No other goals than furthering science. Fame and wealth from researching is not desired.
        \item \textbf{Organized Skepticism}: No dogmatism. Question everything, nothing is sacred or beyond questioning.
    \end{enumerate}
    CUDOS doesn't cover industrial or government research labs, according to John Ziman.
    \\CUDOS can be interpreted \textit{normatively}. Doesn't describe current practice, but is representative of how science \textit{ought} to be.
    
    \subsection{Breaches or problems with scientific integrity}
    \begin{itemize}
        \item Plagiarism (don't copy)
        \item Data manipulation (Millikan vs Ehrenhaft; don't fake your findings by modifying test results)
        \item Data fabrication (Don't make up data; Diederik Stapel)
        \item Authorship (Who comes first in the author list? Who is allowed to be listed as an author? ICMJE guidelines)
        \item Conflict of interest (Who funds your research, and who benefits from it?)
    \end{itemize}
 
 
\section{Philosophers}
Epicurus (341BC - 271BC) 
\\Jeremy Bentham (1748 - 1832) %utilitarian
\\John Stuart Mill (1806 - 1873) %utilitarian
\\Henry Sidgwick (1828 - 1900) %utilitarian
\\Derek Parfitt (1942 - 2017) %utilitarian
\\Peter Singer (1946 - ) %utilitarian
\\Immanuel Kant (1724 - 1804) %deontologist
\\Martin Tisne
\\John Rawls %modern social contract theorist
\end{document}
